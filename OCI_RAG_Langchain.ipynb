{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RAG.png\"  style=\"float: left; margin-right: 10px;\" height=1500/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers \n",
    "! pip install chromadb \n",
    "! pip install wikipedia \n",
    "! pip install langchain \n",
    "! pip install oci "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the langchain libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQA\n",
    "from llms.oci_model_wrapper import OCIModelWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the OCI LLM and Embedding model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "oci_wrapper = OCIModelWrapper()\n",
    "llm = oci_wrapper.llm\n",
    "embedding = oci_wrapper.embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Loader\n",
    "###### [Documentation Link](https://python.langchain.com/docs/modules/data_connection/document_loaders/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = WikipediaLoader(query = \"Oracle Corporation\").load()\n",
    "print(docs[0].metadata)  # meta-information of the Document\n",
    "docs[0].page_content[:300]  # a content of the Document\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Document Transformation\n",
    "##### To accommodate LLMs' token and input size limits, this approach chunks large documents, ensuring they can be summarized without exceeding LLM constraints.\n",
    "###### [Link](https://python.langchain.com/docs/modules/data_connection/document_transformers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_docs = RecursiveCharacterTextSplitter(chunk_size = 900, chunk_overlap = 20, length_function=len)\n",
    "\n",
    "chunks = splitted_docs.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total Chunks created {len(chunks)}\")\n",
    "for i, _ in enumerate(chunks):\n",
    "    print(f\"chunk# {i}, size: {chunks[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the embedding data in a vector store (Chroma DB)\n",
    "###### [Link](https://python.langchain.com/docs/modules/data_connection/text_embedding/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'demo_db_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current limitation of the 96 elements in input array\n",
    "chunk_size = 96\n",
    "\n",
    "# Calculate the total number of chunks needed to process all elements\n",
    "# This is simply the length of the chunks array divided by the chunk size\n",
    "num_chunks = len(chunks) // chunk_size\n",
    "\n",
    "# If there are any remaining elements after forming full chunks, add one more chunk for them\n",
    "if len(chunks) % chunk_size > 0:\n",
    "    num_chunks += 1\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    # Calculate the start index for the current chunk\n",
    "    start_idx = i * chunk_size\n",
    "    \n",
    "    # Calculate the end index for the current chunk\n",
    "    # This is the start index plus the chunk size, but it should not exceed the length of the chunks array\n",
    "    end_idx = min(start_idx + chunk_size, len(chunks))\n",
    "    \n",
    "    # Slice the chunks array to get the current chunk\n",
    "    current_chunk = chunks[start_idx:end_idx]\n",
    "    \n",
    "    # Process the current chunk\n",
    "    vectordb = Chroma.from_documents(documents=current_chunk, embedding=embedding,persist_directory=persist_directory)\n",
    "    vectordb.persist()\n",
    "    vectordb = None\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the ChromaDB from a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Get the DB to check for a valid file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrievers\n",
    "### Use retriever to return relevant document\n",
    "###### [Link](https://python.langchain.com/docs/modules/data_connection/retrievers/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "query = \"Who was the first CEO of Oracle?\"\n",
    "docs = vectordb.similarity_search(query)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run test querries to return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(\"Who was the first CEO of Oracle?\")\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pass search [arguments](https://python.langchain.com/docs/modules/data_connection/retrievers/vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})\n",
    "retriever.search_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a chain \n",
    "###### [Link](https://api.python.langchain.com/en/latest/chains/langchain.chains.retrieval_qa.base.RetrievalQA.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### [Optional] Create a handler to get verbose information. Helpful while troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose, set_debug\n",
    "set_debug(False)\n",
    "set_verbose(False)\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "handler = StdOutCallbackHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RetrievalQA Chain with map_reduce as chain type. Enable callback variable to get verbose output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the chain to answer questions \n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                  chain_type= \"map_reduce\", \n",
    "                                  retriever=retriever, \n",
    "                                  return_source_documents=True,\n",
    "                                    #callbacks=[handler],\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to return relevant output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(response):\n",
    "    # Check if 'result' key exists in the response and print its value\n",
    "    if 'result' in response:\n",
    "        print(f\"Result: {response['result']} \\n\\n\")\n",
    "    else:\n",
    "        print(\"Result: No result found.\\n\\n\")\n",
    "    \n",
    "    # Check if 'source_documents' key exists and it is a list\n",
    "    if 'source_documents' in response and isinstance(response['source_documents'], list):\n",
    "        # Iterate through each source document in the list\n",
    "        for i, src in enumerate(response['source_documents'], start=1):\n",
    "            # Access 'metadata' directly assuming 'src' is an object with a 'metadata' attribute\n",
    "            # Check if 'metadata' exists and is a dictionary, then access 'source'\n",
    "            if hasattr(src, 'metadata') and isinstance(src.metadata, dict):\n",
    "                source_url = src.metadata.get('source', 'No source found')\n",
    "            else:\n",
    "                source_url = 'No source found'\n",
    "            print(f\"Source {i}: {source_url}\")\n",
    "    else:\n",
    "        print(\"Source Documents: No source documents found.\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When did Oracle partner with microsoft? Answer in one line\"\n",
    "llm_response = qa_chain.invoke(query)\n",
    "print_output(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Who is the current CEO of Oracle?\"\n",
    "llm_response = qa_chain.invoke(query)\n",
    "print_output(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What was the original name of Oracle?\"\n",
    "llm_response = qa_chain.invoke(query)\n",
    "print_output(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What products does Oracle sell? Anser the question in bulltet points.\"\n",
    "llm_response = qa_chain.invoke(query)\n",
    "print_output(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When did Oracle come into an existence? Answer in one line\"\n",
    "llm_response = qa_chain.invoke(query)\n",
    "print_output(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"When did Oracle aquire Cerner?Answer in one line\"\n",
    "llm_response = qa_chain.invoke(query)\n",
    "print_output(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Name few hardware products. The answer should be in bullet points\"\n",
    "llm_response = qa_chain.invoke(query)\n",
    "print_output(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "Could you analyze and discuss the ethical framework and values that guide Oracle Corporation? Specifically, \n",
    "examine how these principles influence Oracle's decision-making processes, \n",
    "corporate policies, and its approach to social responsibility. \n",
    "Provide examples to illustrate where the company's 'moral compass' points, \n",
    "especially in situations involving significant ethical dilemmas or decisions.\n",
    "'''\n",
    "llm_response = qa_chain.invoke(query)\n",
    "print_output(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "Please calculate the total amount Oracle has spent on acquisitions where the purchase price is publicly disclosed. \n",
    "Exclude any acquisitions where the purchase price has not been shared. \n",
    "Provide the final sum in USD, and break down the calculation using a mathematical equation. \n",
    "Ensure the explanation is clear, incorporating each acquisition's cost into the equation to arrive at the total expenditure.\n",
    "'''\n",
    "llm_response = qa_chain.invoke(query)\n",
    "print_output(llm_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
